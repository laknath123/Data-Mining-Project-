---
title: "Group-L-Project"
author: "Laknath Dias Gunathilake"
date: "March 13, 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Exploration  

In this section we explore the various connection types and services to determine if we are able to detect any interesting patterns or anomolies with regards to bytes been transferred and the duration of the connections. 

```{r }
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)

df <- read.csv("network_traffic.csv")

p1 <- qplot(df$duration, geom="histogram")
p2 <- qplot(df$protocol_type, geom="bar")
p3 <- qplot(df$service, geom="bar")
p4 <- qplot(df$src_bytes, geom="histogram")
p5 <- qplot(df$dst_bytes, geom="histogram")
p6 <- qplot(df$flag, geom="bar")
p7 <- qplot(df$land, geom="bar")
p8 <- qplot(df$wrong_fragment, geom="histogram")
p9 <- qplot(df$urgent, geom="histogram")
p10 <- qplot(df$hot, geom="histogram")
p11 <- qplot(df$num_failed_logins, geom="histogram")
p12 <- qplot(df$logged_in, geom="bar")
p13 <- qplot(df$num_compromised, geom="histogram")
p14 <- qplot(df$root_shell, geom="bar")
p15 <- qplot(df$su_attempted, geom="bar")
p16 <- qplot(df$num_root, geom="histogram")
p17 <- qplot(df$num_file_creations, geom="histogram")
p18 <- qplot(df$num_shells, geom="histogram")
p19 <- qplot(df$num_access_files, geom="histogram")
p20 <- qplot(df$num_outbound_cmds, geom="histogram")
p21 <- qplot(df$is_hot_login, geom="bar")
p22 <- qplot(df$is_guest_login, geom="bar")
p23 <- qplot(df$is_intrusion, geom="bar")
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p12, p13, ncol=3)
grid.arrange(p14, p15, p16, p17, p18, p19, p20, p21, p22, p23, ncol=3)


#Adding a boxplots src and dst bytes by service
options(scipen=999)
ggplot(data = df,aes(x = as.factor(service),y = src_bytes))+
        geom_boxplot()+
        coord_flip()+ylab("number of data bytes from source to destination ")+xlab("Service")

ggplot(data = df,aes(x = as.factor(service),y = dst_bytes))+
          geom_boxplot()+
          coord_flip()+
          ylab("number of data bytes from destination to source")+xlab("Service")

```
#Univariate Analysis

+ Looking at the data above it is evident that a majority of the continous variables are highly skewed with most values centering close to zero and and a few large values that skewing the distributions to the right.

+ it also evident that there are a number of variables that contain only zero's 

+ accordingly we hope to look at a bivariate analysis between two variables of interest in the next section


## Analyzing byte transfers for Different Service Types

We wanted to understand the bytes transferred between the different services `r unique(df$service)`


+  It is evident that the http ftp_data,http and smtp data have large variation in the number of bytes sent from source to destination with http data having an extreme outlier

+ When looking at byte transfer from destination to the source it is evident that http, and telnet have large variations.
It is evident that "Telnet is not a secure protocol and is unencrypted. By monitoring a user's connection, anyone can access a person's username, password and other private information that is typed over the Telnet session in plaintext. With this information, access can be gained to the user's device." Source("https://searchnetworking.techtarget.com/definition/Telnet")
According this is quite alarming that we large number of bytes being sent from destination to the source using the telnet service type.

# Understanding Duration for different Service Types

```{r}
ggplot(data = df,aes(x = as.factor(service),y = duration ))+
          geom_boxplot()+
          coord_flip()+xlab("Service Types")


```

+ It is evident telnet and service type tagged others have the highest duration or the number of second in the connection. 
It is also evident that others seem to have multiple outliers including an outlier that incidates there was a connection that 
lasted for more than `r max(df$duration)/(60*60)` or 6 hours




```{r}
# drop useless columns
df <- select(df, -c(num_outbound_cmds, land, num_failed_logins, wrong_fragment, urgent, is_host_login, su_attempted))

# Clean is_intrusion column
df$is_intrusion <- ifelse(df$is_intrusion == 1, 1, 0)

# convert to factors
df$is_intrusion <- as.factor(df$is_intrusion)
df$protocol_type <- as.factor(df$protocol_type)
df$service <- as.factor(df$service)
df$flag <- as.factor(df$flag)
df$logged_in <- as.factor(df$logged_in)
df$root_shell <- as.factor(df$root_shell)
df$is_guest_login <- as.factor(df$is_guest_login)

summary(df)
```




# Class Metrics Function
```{r}
classMetrics <- function(score, y, cutoff, 
                         type = c("all", "accuracy", "sensitivity", 
                                  "specificity", "ppv", "npv", "precision", 
                                  "recall")) {
  
              
  # classify the observations based on score and cutoff
  observed <- y
  predicted <- ifelse(score >= cutoff,1,0)
  
      # Form confusion matrix
  conf<-table(predicted,observed)
  
  # Use the appropriate entries in the confusion matrix to calculate all metrics:
  # accuracy, sensitivity, specificity, ppv, npv, precision (which is the same as ppv), recall (which is the same as sensitivity)
  #accuracy <-
  
  accuracy<- round((conf[4]+conf[1])/sum(conf),6)
  sensitivity <- (conf[4])/(conf[3]+conf[4])
  specificity <-  conf[1]/(conf[1]+conf[2])
  ppv         <- conf[4]/(conf[4]+conf[2])
  npv         <- conf[1]/(conf[1]+conf[3])
  precision   <- ppv
  recall      <- sensitivity
  
  # I'm giving you the exact names you should use in your output dataframe  
  metric.names <- c("accuracy", "sensitivity", "specificity", 
                    "ppv", "npv", "precision", "recall")

  # Form into data frame
  value <- c(accuracy, sensitivity, specificity, 
                    ppv, npv, precision, recall)
  
  
  
  # Your data frame should contain ONLY ONE COLUMN named "value"
  # assign the metric.names above as the rownames of your data frame (just as the rownames, not as a second column!)
  df <- data.frame(row.names = metric.names,value)
  
  full_list<- list(conf,df)
  names(full_list) <- c("conf.mat", "perf")
  #full_list <<- full_list
  # Return a list containing the confusion matrix and the data frame of the metrics
  # If "all", return all metrics. Otherwise, return just the requested subset of metrics
  if ("all" %in% type){
    return(full_list)
  } else {
    full_list[[2]]<- full_list[[2]]%>%
          filter(row.names(full_list[[2]]) %in% type)
    return(full_list)
  }
}

```

#Plot Class 
```{r}
plotClassMetrics <- function(score, y, xvar = NULL, yvar = c("accuracy", "sensitivity", 
                                  "specificity", "ppv", "npv", "precision", 
                                  "recall"),
                             flip.x = FALSE) {
  
  # matches the user-input yvar argument against the list of valid options specified in the function header
  yvar <- match.arg(yvar)
  
  # If there are a lot of (more than 100) unique score values, just calculate the metrics
  # along an evenly spaced grid of 100 scores.
  unique.scores <- unique(score)
  if(length(unique.scores) > 100) {
    cutoff.seq <- sample(unique.scores, 100, replace = FALSE)
  } else { # otherwise just use the unique score values to calculate the metrics
    cutoff.seq <- unique.scores
  }
  
  # number of score values to evaluate the metrics
  n <- length(cutoff.seq)
  
  # initialize the vectors to record the x & y coordinates
  x.out <- numeric(n)
  y.out <- numeric(n)
  # Loop over all values of the score and calculate the performance metrics
  for(i in 1:n) {
    if(!is.null(xvar)) { # specified metric as x axis values
      # call classMetrics to calculate the metrics and record the values
      metrics <- classMetrics(score, y, cutoff = cutoff.seq[i], type = c(xvar, yvar))
      x.out[i] <- metrics$perf[xvar, 1]
      y.out[i] <- metrics$perf[yvar, 1]
    } else { # score as x axis values
      # call classMetrics to calculate the metrics and record the values
      metrics <- classMetrics(score, y, cutoff = cutoff.seq[i], type = c(yvar))
      x.out[i] <- cutoff.seq[i]
      y.out[i] <- metrics$perf[yvar, 1]
    }
  }

  # flip x values if required
  if(flip.x) {
    x.out <- 1 - x.out
  }
  
  # Combine metrics into a data frame
  df.out <- data.frame(score = cutoff.seq, x = x.out, y = y.out)
  
  # Reorder the data frame in increasing order of the x-axis variable
  df.out <- df.out[order(df.out$score), ]
  
  # De-duplicate x-axis
  df.out <- subset(df.out, subset = !duplicated(df.out$x))
  
  # determine the x-axis label
  if(!is.null(xvar)) {
    x.text <- ifelse(flip.x, paste0("1 - ", xvar), xvar)
  } else {
    x.text <- "score"
  }
  
  # Construct line plot
  print(qplot(data = df.out, x = x, y = y, geom = "line",
              xlab = ifelse(is.null(xvar), "score", x.text),
              ylab = yvar, ylim = c(0, 1)))
}
```


# Identifying the imbalances in dataset

```{r}
ggplot(data = df,aes(x = is_intrusion))+
      geom_bar(aes(fill=is_intrusion))+ ggtitle("Class Imbalance")

```
##Oversampling (Upsampling) the minority class

+ It is evident from the above graph that we have a problem of imbalanced classes- Meaning we have far fewer postive classes
or actual intrusions compared to benign intrusions.

+ Since we cannot collect aditional data in this instance, such a situattion requires us to balance the classes by introducing
resampling to the dataset. 

+ Since the minority class is underpresented, we decided to oversample the `r is_intrusion==1` observations



```{r}
df<- df%>%select(-c(7:14))%>%select(-c(1,7))


# Upsample the data to artifically overcome sample imbalance
df.more.idx <- sample(which(df$is_intrusion == 1), 900, replace = TRUE)

set.seed(981)


df.upsample <- rbind(df,
                        df[df.more.idx, ])


ggplot(data = df.upsample,aes(x = is_intrusion))+
      geom_bar(aes(fill=is_intrusion))+ ggtitle("Classes Balanced")

```
+ The above bar graph seems to indicate now that we have an approximate balance between intrusions equal to one and zero


```{r}
# Randomly select 20% of the data to be held out for model validation
test.indexes <- sample(1:nrow(df.upsample), 
                       round(0.2 * nrow(df.upsample)))


train.indexes <- setdiff(1:nrow(df.upsample), test.indexes)



df.train <- df.upsample[train.indexes,]
df.test <- df.upsample[test.indexes,]


```



### Training the tree
```{r}
intrusion.tree <- rpart(is_intrusion ~ ., df.train)


plot(intrusion.tree)
text(intrusion.tree)


intrusion.party <- as.party(intrusion.tree)

plot(intrusion.party)

print(intrusion.party)

```


### Growing and Pruning the Tree
```{r}
intrusion.full <- rpart(is_intrusion ~ ., data = df.train, 
                        control = rpart.control(minsplit=10, cp=0.002))

# Run the `plotcp` command on this tree. Also look at the `cptable` attribute of `marketing.full`
plotcp(intrusion.full)

intrusion.full$cptable

mycp <- 0.046

intrusion.pruned<- prune(intrusion.full,cp= mycp)


print(intrusion.pruned)
```
+ After trying different min split levels for training the dataset I found minsplit level of 10 to result in better performance when training the tree.


### Pruned Tree
```{r}
df.pruned.party <- as.party(intrusion.pruned)
plot(df.pruned.party, gp = gpar(fontsize = 7))
```

+ it is evident that in the pruned tree we split by service and flag to classify observations as intrusions or not.  

### Using the pruned tree on the test dataset
```{r}
my_pred<- predict(intrusion.pruned, df.test, type="prob")[,1]


classMetrics(my_pred, df.test$is_intrusion,cutoff = 0.20)
```

## Visualizing Sensitivity and Specificity

```{r}
plotClassMetrics(my_pred, df.test$is_intrusion, 
                 xvar = "accuracy", yvar = "specificity", 
                 flip.x = TRUE)
```



+ it is evident that our tree model has a sensitivity of 0.66. Sensitivity or recall is when given the observations that had the event (intrusions), the observations that were correctly classified to have the event.

+ We also know that a classifier with high Sensitivity is desirable when False Negatives (e.g., failing to detect an intrusion ) are more costly than False Positives(flagging a case an attemt that turns out to non intrusive)


## Building a Random forest 

Since Decision trees provided a high degree of recall, we also wanted look at random forests

```{r}
intrusion.rf <- randomForest(is_intrusion ~.,data=df.train)
intrusion.rf


```

+ Based on the importance plot, we know that service, flag, src_bytes, dst_bytes and protocol type are important 

```{r}
varImpPlot (intrusion.rf)

```



```{r}
rf.test.prob <- predict(intrusion.rf, newdata = df.test, type = "prob")[,1]

classMetrics(rf.test.prob, df.test$is_intrusion, cutoff = 0.3)

```

```{r}
# Logistic Regression

# fit logistic regression on train set
glm.fits <- glm(is_intrusion∼., data=df.train ,family=binomial)
summary(glm.fits)

# predict on test set
glm.probs <- predict(glm.fits,df.test, type="response")

cutoff <- 0.5
glm.pred <- 1:length(glm.probs)
glm.pred[glm.probs > cutoff] <- 1
glm.pred[glm.probs < cutoff] <- 0

table(glm.pred, df.test$is_intrusion)
```

```{r}
# source: https://towardsdatascience.com/clustering-datasets-having-both-numerical-and-categorical-variables-ed91cdca0677

# Clustering
intrusion_df <- filter(df, is_intrusion == 1)

# build a df of gower distances
library(cluster)
gower_df <- daisy(intrusion_df, metric="gower", type=list(logration=2))
summary(gower_df)

# calculate silhouette width to determine number of clusters
silhouette <- c()
silhouette = c(silhouette, NA)

# calculate distances using medoids instead of centroids
# this takes a long time to run
for(i in 2:10){
  pam_clusters = pam(as.matrix(gower_df),
                 diss = TRUE,
                 k = i)
  silhouette = c(silhouette,pam_clusters$silinfo$avg.width)
}

library(Rtsne)
# plot silhouette widths based on number of clusters 
plot(1:10, silhouette,
     xlab = "Clusters",
     ylab = "Silhouette Width")
lines(1:10, silhouette)

pam <- pam(gower_df, diss = TRUE, k = 6)
# These are the median values of our clusters
# They represent the characteristics of each cluster
intrusion_df[pam$medoids, ]

# plot the data in 2-dimensional space
tsne_object <- Rtsne(gower_df, is_distance = TRUE)
tsne_df <- tsne_object$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam$clustering))

ggplot(aes(x = X, y = Y), data = tsne_df) +
  geom_point(aes(color = cluster))
```









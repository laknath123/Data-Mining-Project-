---
title: "Group-L-Project"
author: "Laknath Dias Gunathilake, Alexander Talbott, and Meghna Subramanian"
date: "March 13, 2021"
output: html_document
---
# Introduction

This is Group L's group project in 95-791 Data Mining at Carnegie Mellon University, Heinz College, Spring 2021. The project entails an analysis of the network infrastructure of XYZ Bank in St. Loius, Missouri.
 
The bank recently discovered many network intrusions and labelled them in a data set with other information. This project attempts to build a data mining approach to identifying such network intrusions in the future.
As part of the"network_traffic.csv" file, we have several variables that help understand an activity's characteristics, such as different protocols, service types, and data bytes. Our response variable for analysis is the "is_intrusions" variable that tells us whether an attempt/unusual activity led to an intrusion where 1 is an actual intrusion and 0 is a benign session.
 
This project will clean and explore the data, build different models to detect and categorize likely types of intrusions and predict future intrusions.
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)

library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
library(caret)
library(leaps)
library(Rtsne)
library(kableExtra)

df <- read.csv("network_traffic.csv")

cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

set.seed(981)
```

# Section 1: Exploratory Data Analysis

## Data Cleaning
Firstly, the data provided by the bank is not perfect. Below, we drop the columns that will not be useful in our analysis. We dropped variables that contain the same value for every instance since they don't add any variation to our dataset and save computational time.  Secondly, we convert the data to datatypes R can better understand.
```{r}
# drop useless columns
df <- select(df, -c(num_outbound_cmds, land, num_failed_logins, wrong_fragment, urgent, is_host_login, su_attempted))

# Clean is_intrusion column
df$is_intrusion <- ifelse(df$is_intrusion == 1, 1, 0)

# convert to factors
df$is_intrusion <- as.factor(df$is_intrusion)
df$protocol_type <- as.factor(df$protocol_type)
df$service <- as.factor(df$service)
df$flag <- as.factor(df$flag)
df$logged_in <- as.factor(df$logged_in)
df$root_shell <- as.factor(df$root_shell)
df$is_guest_login <- as.factor(df$is_guest_login)
```

## Data Exploration  
This section explores the various connection types and services to determine if we can detect any interesting patterns or anomalies regarding bytes and the connection durations. Initially, we did a univariate variable analysis through bar charts and box plots. We then moved on to do a multivariate analysis to understand relationships between different variables. Findings from our study are explained below.

```{r }
p1 <- qplot(df$duration, geom="histogram", xlab="Duration")
p2 <- qplot(df$protocol_type, geom="bar", xlab="Protocol Type")
p3 <- qplot(df$service, geom="bar", xlab="Service")
p4 <- qplot(df$src_bytes, geom="histogram", xlab="Bytes from Source to Destination")
p5 <- qplot(df$dst_bytes, geom="histogram", xlab="Bytes from Destination to Source")
p6 <- qplot(df$flag, geom="bar", xlab="Error Status")
p7 <- qplot(df$hot, geom="histogram", xlab="Hot Indicators")
p8 <- qplot(df$logged_in, geom="bar", xlab="Logged In")
p9 <- qplot(df$num_compromised, geom="histogram", xlab="Number Compromised")
p10 <- qplot(df$root_shell, geom="bar", xlab="Root Shell")
p11 <- qplot(df$num_root, geom="histogram", xlab="Number of Root Commands")
p12 <- qplot(df$num_file_creations, geom="histogram", xlab="File Creations")
p13 <- qplot(df$num_shells, geom="histogram", xlab="Number of Shells")
p14 <- qplot(df$num_access_files, geom="histogram", xlab="Accessed Files")
p15 <- qplot(df$is_guest_login, geom="bar", xlab="Guest Login")
p16 <- qplot(df$is_intrusion, geom="bar", xlab="Intrusion")
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, ncol=3)
grid.arrange(p10, p12, p13, p14, p15, p16, ncol=3)

#Adding a boxplots src and dst bytes by service
options(scipen=999)
ggplot(data = df,aes(x = as.factor(service),y = src_bytes))+
        geom_boxplot()+
        coord_flip()+ylab("number of data bytes from source to destination ")+xlab("Service")

ggplot(data = df,aes(x = as.factor(service),y = dst_bytes))+
          geom_boxplot()+
          coord_flip()+
          ylab("number of data bytes from destination to source")+xlab("Service")
```
## Univariate Analysis

The data above shows that most continuous variables are highly skewed, with most values centred close to zero and a few large values that skew the distributions to the right. It is also evident that several variables contain only zeros. Based on the above analysis, we moved on to look at a bivariate analysis between four variables of interest.

## Bivariate Analysis
```{r}
ggplot(data = df,aes(x = as.factor(service),y = duration ))+
          geom_boxplot()+
          coord_flip()+xlab("Service Types")
ggplot(data = df,aes(x = as.factor(is_intrusion)  ,y = duration))+
          geom_boxplot()+
          coord_flip()+xlab("Duration of intrusions")
```
We started by understanding the bytes transferred between the different services `r unique(df$service)`
 
Based on the boxplots above, it is evident that the http ftp_data, http, Telnet, and smtp data have a large variation in the number of bytes sent from source to destination, with http data having an extreme outlier. The 'others' service types have multiple outliers, including an outlier indicating a connection that lasted for more than `r max(df$duration)/(60*60)` or 6 hours.
 
Telnet and service type tagged others have the highest duration or the number of second in the connection. It is evident that Telnet is not a secure protocol and is unencrypted. By monitoring a user's connection, anyone can access a person's username, password and other private information that is typed over the Telnet session in plaintext. With this information, access can be gained to the user's device("https://searchnetworking.techtarget.com/definition/Telnet").
Based on this information, it is pretty alarming that many bytes are being sent from the destination to the source using the telnet service type.
 
 
Based on the boxplot on the duration of intrusion, we can see that non-intrusions have many outliers, making it difficult to draw conclusions. Intrusions, on the other hand, have more variations with a larger interquartile range. The median intrusion also has a longer duration than the median non-intrusions.


## Class Metrics Function
```{r}
classMetrics <- function(score, y, cutoff, 
                         type = c("all", "accuracy", "sensitivity", 
                                  "specificity", "ppv", "npv", "precision", 
                                  "recall")) {
  
              
  # classify the observations based on score and cutoff
  observed <- y
  predicted <- ifelse(score >= cutoff,1,0)
  
      # Form confusion matrix
  conf<-table(predicted,observed)
  
  # Use the appropriate entries in the confusion matrix to calculate all metrics:
  # accuracy, sensitivity, specificity, ppv, npv, precision (which is the same as ppv), recall (which is the same as sensitivity)
  #accuracy <-
  
  accuracy<- round((conf[4]+conf[1])/sum(conf),6)
  sensitivity <- (conf[4])/(conf[3]+conf[4])
  specificity <-  conf[1]/(conf[1]+conf[2])
  ppv         <- conf[4]/(conf[4]+conf[2])
  npv         <- conf[1]/(conf[1]+conf[3])
  precision   <- ppv
  recall      <- sensitivity
  
  # I'm giving you the exact names you should use in your output dataframe  
  metric.names <- c("accuracy", "sensitivity", "specificity", 
                    "ppv", "npv", "precision", "recall")

  # Form into data frame
  value <- c(accuracy, sensitivity, specificity, 
                    ppv, npv, precision, recall)
  
  
  
  # Your data frame should contain ONLY ONE COLUMN named "value"
  # assign the metric.names above as the rownames of your data frame (just as the rownames, not as a second column!)
  df <- data.frame(row.names = metric.names,value)
  
  full_list<- list(conf,df)
  names(full_list) <- c("conf.mat", "perf")
  #full_list <<- full_list
  # Return a list containing the confusion matrix and the data frame of the metrics
  # If "all", return all metrics. Otherwise, return just the requested subset of metrics
  if ("all" %in% type){
    return(full_list)
  } else {
    full_list[[2]]<- full_list[[2]]%>%
          filter(row.names(full_list[[2]]) %in% type)
    return(full_list)
  }
}


plotClassMetrics <- function(score, y, xvar = NULL, yvar = c("accuracy", "sensitivity", 
                                  "specificity", "ppv", "npv", "precision", 
                                  "recall"),
                             flip.x = FALSE) {
  
  # matches the user-input yvar argument against the list of valid options specified in the function header
  yvar <- match.arg(yvar)
  
  # If there are a lot of (more than 100) unique score values, just calculate the metrics
  # along an evenly spaced grid of 100 scores.
  unique.scores <- unique(score)
  if(length(unique.scores) > 100) {
    cutoff.seq <- sample(unique.scores, 100, replace = FALSE)
  } else { # otherwise just use the unique score values to calculate the metrics
    cutoff.seq <- unique.scores
  }
  
  # number of score values to evaluate the metrics
  n <- length(cutoff.seq)
  
  # initialize the vectors to record the x & y coordinates
  x.out <- numeric(n)
  y.out <- numeric(n)
  # Loop over all values of the score and calculate the performance metrics
  for(i in 1:n) {
    if(!is.null(xvar)) { # specified metric as x axis values
      # call classMetrics to calculate the metrics and record the values
      metrics <- classMetrics(score, y, cutoff = cutoff.seq[i], type = c(xvar, yvar))
      x.out[i] <- metrics$perf[xvar, 1]
      y.out[i] <- metrics$perf[yvar, 1]
    } else { # score as x axis values
      # call classMetrics to calculate the metrics and record the values
      metrics <- classMetrics(score, y, cutoff = cutoff.seq[i], type = c(yvar))
      x.out[i] <- cutoff.seq[i]
      y.out[i] <- metrics$perf[yvar, 1]
    }
  }

  # flip x values if required
  if(flip.x) {
    x.out <- 1 - x.out
  }
  
  # Combine metrics into a data frame
  df.out <- data.frame(score = cutoff.seq, x = x.out, y = y.out)
  
  # Reorder the data frame in increasing order of the x-axis variable
  df.out <- df.out[order(df.out$score), ]
  
  # De-duplicate x-axis
  df.out <- subset(df.out, subset = !duplicated(df.out$x))
  
  # determine the x-axis label
  if(!is.null(xvar)) {
    x.text <- ifelse(flip.x, paste0("1 - ", xvar), xvar)
  } else {
    x.text <- "score"
  }
  
  # Construct line plot
  print(qplot(data = df.out, x = x, y = y, geom = "line",
              xlab = ifelse(is.null(xvar), "score", x.text),
              ylab = yvar, ylim = c(0, 1)))
}
```

## Oversampling (Upsampling) the minority class
```{r}
ggplot(data = df,aes(x = is_intrusion))+
      geom_bar(aes(fill=is_intrusion))+ ggtitle("Class Imbalance")

```
+ It is evident from the above graph that we have a problem of imbalanced classes- Meaning we have far fewer postive classes
or actual intrusions compared to benign intrusions.

+ Since we cannot collect additional data in this instance, such a situattion requires us to balance the classes by introducing
resampling to the dataset. 

+ Since the minority class is underpresented, we decided to oversample the `r is_intrusion==1` observations

```{r}
tree.df <- df%>%select(-c(7:14))%>%select(-c(1,7))


# Upsample the data to artifically overcome sample imbalance
df.more.idx <- sample(which(df$is_intrusion == 1), 900, replace = TRUE)


df.upsample <- rbind(tree.df,
                        tree.df[df.more.idx, ])


ggplot(data = df.upsample,aes(x = is_intrusion))+
      geom_bar(aes(fill=is_intrusion))+ ggtitle("Classes Balanced")

```
+ The above bar graph seems to indicate now that we have more balance between intrusions equal to one and zero

```{r}
# Randomly select 20% of the data to be held out for model validation
test.indexes <- sample(1:nrow(df.upsample), 
                       round(0.2 * nrow(df.upsample)))


train.indexes <- setdiff(1:nrow(df.upsample), test.indexes)



df.train <- df.upsample[train.indexes,]
df.test <- df.upsample[test.indexes,]
```

# Section 2: Methodology
## Decision Trees

We first fitted a decision tree on the training data set.  We also tried different split values and decided on 10 as the min split. We then used the rpart function to grow the tree. Then we plotted the complexity parameter vs the relative error of the trained model and chose a complexity parameter that minimizes the relative error. We then used the chosen complexity error on the test set. 

### Training the tree
```{r}
intrusion.tree <- rpart(is_intrusion ~ ., df.train)


plot(intrusion.tree)
text(intrusion.tree)


intrusion.party <- as.party(intrusion.tree)

plot(intrusion.party)

print(intrusion.party)

```
This is the original result from training the tree before pruning.

### Growing and Pruning the Tree
```{r}
intrusion.full <- rpart(is_intrusion ~ ., data = df.train, 
                        control = rpart.control(minsplit=10, cp=0.002))

# Run the `plotcp` command on this tree. Also look at the `cptable` attribute of `marketing.full`
plotcp(intrusion.full)

intrusion.full$cptable

mycp <- 0.046

intrusion.pruned<- prune(intrusion.full,cp= mycp)


print(intrusion.pruned)
```
We used this plot to determine the cp-value with the lowest relative error.


### Pruned Tree
```{r}
df.pruned.party <- as.party(intrusion.pruned)
plot(df.pruned.party, gp = gpar(fontsize = 7))
```
The root node was service and we see that the variable service and flag had the highest predictive power.


## Building a Random forest 

Since Decision trees provided a high degree of recall, we also wanted look at random forests

### Building a Random forest 
```{r}
intrusion.rf <- randomForest(is_intrusion ~.,data=df.train)
intrusion.rf
```

## Logistic Regression
In this section, we will attempt to separate intrusions from benign sessions using logistic regression. First we will select the subset of variables that will be best to fit the logisitc regression model.
```{r}
df.subset <- regsubsets(is_intrusion ~ .,
                        data = df,
                        nbest = 1,
                        nvmax = NULL,
                        method = "exhaustive", 
                        really.big = TRUE)

nvmax = length(df) # all variables
df.subset_bestmodels <- list()
#Iterate to get the best model at each number of coeficients
#Remember that we limited our nvmax to 5!
for(i in 1:nvmax) {
  df.subset_bestmodels[[i]] <- c(coef(df.subset, i))
}
```
This shows us which variables are included at each step of the best subset selection. We start with a model consisting of one variable then work up to a full model with all 16 predictors included. We will now track the metrics of these models to pick which one is ideal for regression.

```{r}
df.summary<-summary(df.subset)

num_variables<-seq(1,length(df.summary$rss))

plot_RSS<-ggplot(data = data.frame(df.summary$rss),
                 aes(x=num_variables,y=df.summary$rss))+
  geom_line()+
  geom_point(x=which.min(df.summary$rss),
             y=min(df.summary$rss),aes(color="red"),
             show.legend = FALSE)+
  xlab("# Variables")+
  ylab("RSS")+
  theme_bw()

plot_R_sq<-ggplot(data = data.frame(df.summary$rsq),
                 aes(x=num_variables,y=df.summary.rsq))+
  geom_line()+
  geom_point(x=which.max(df.summary$rsq),
             y=max(df.summary$rsq),aes(color="red"),
             show.legend = FALSE)+
  xlab("# Variables")+
  ylab("R-sq")+
  theme_bw()

plot_BIC<-ggplot(data = data.frame(df.summary$bic),
                 aes(x=num_variables,y=df.summary.bic))+
  geom_line()+
  geom_point(x=which.min(df.summary$bic),
             y=min(df.summary$bic),aes(color="red"),
             show.legend = FALSE)+
  xlab("# Variables")+
  ylab("BIC")+
  theme_bw()

plot_AIC<-ggplot(data = data.frame(df.summary$cp),
                 aes(x=num_variables,y=df.summary.cp))+
  geom_line()+
  geom_point(x=which.min(df.summary$cp),
             y=min(df.summary$cp),aes(color="red"),
             show.legend = FALSE)+
  xlab("# Variables")+
  ylab("AIC")+
  theme_bw()


grid.arrange(plot_RSS, plot_R_sq,plot_AIC,plot_BIC, ncol=2,nrow=2)
best.sub.num <- which.min(df.summary$bic)
best.sub.cols <- names(df.subset_bestmodels[[best.sub.num]][2:best.sub.num+1])
best.sub.cols
```
Here we see the RSS, R2, AIC, and BIC of all of the above models. We can see that errors are minimized and R2 is maximized at `r best.sub.num` variables included with severely diminishing returns after that amount. Therefore, we will select the subset with `r best.sub.num` variables to put into the logistic regression model.

```{r}
# train/test split
test.indexes <- sample(1:nrow(df.upsample), 
                       round(0.2 * nrow(df.upsample)))

train.indexes <- setdiff(1:nrow(df.upsample), test.indexes)
df.log.train <- df[train.indexes,]
df.log.test <- df[test.indexes,]

glm.fits <- glm(is_intrusionâˆ¼service + flag + src_bytes + dst_bytes + logged_in + num_compromised + is_guest_login, data=df.log.train ,family="binomial", maxit=100)
kable(summary(glm.fits)$coef)

# predict on test set
glm.probs <- predict(glm.fits,df.log.test, type="response")
cutoff <- 0.5
glm.pred <- rep(0, length(glm.probs))
glm.pred[glm.probs > cutoff] <- 1

table(glm.pred, df.log.test$is_intrusion)

```

# Section 3: 
## Evaluating Models
### Decision Trees
```{r}
my_pred<- predict(intrusion.pruned, df.test, type="prob")[,1]
classMetrics(my_pred, df.test$is_intrusion,cutoff = 0.20)
plotClassMetrics(my_pred, df.test$is_intrusion, 
                 xvar = "accuracy", yvar = "specificity", 
                 flip.x = TRUE)
```
+ it is evident that our tree model has a sensitivity of 0.66. Sensitivity or recall is when given the observations that had the event (intrusions), the observations that were correctly classified to have the event.

+ We also know that a classifier with high Sensitivity is desirable when False Negatives (e.g., failing to detect an intrusion ) are more costly than False Positives(flagging a case an attemt that turns out to non intrusive)

### Random Forests
```{r}
rf.test.prob <- predict(intrusion.rf, newdata = df.test, type = "prob")[,1]

classMetrics(rf.test.prob, df.test$is_intrusion, cutoff = 0.3)
varImpPlot (intrusion.rf)
```
+ Based on the importance plot, we know that service, flag, src_bytes, dst_bytes and protocol type are important 

### Logistic Regression
```{r}
classMetrics(glm.pred, df.log.test$is_intrusion, cutoff = 0.20)
plotClassMetrics(glm.pred, df.log.test$is_intrusion, 
                 xvar = "accuracy", yvar = "specificity", 
                 flip.x = TRUE)
```

## Clustering
```{r}
# source: https://towardsdatascience.com/clustering-datasets-having-both-numerical-and-categorical-variables-ed91cdca0677

# Clustering
intrusion_df <- filter(df, is_intrusion == 1)

# build a df of gower distances
gower_df <- daisy(intrusion_df, metric="gower", type=list(logration=2))
summary(gower_df)

# calculate silhouette width to determine number of clusters
silhouette <- c()
silhouette = c(silhouette, NA)

# calculate distances using medoids instead of centroids
# this takes a long time to run
for(i in 2:10){
  pam_clusters = pam(as.matrix(gower_df),
                 diss = TRUE,
                 k = i)
  silhouette = c(silhouette,pam_clusters$silinfo$avg.width)
}

# plot silhouette widths based on number of clusters 
plot(1:10, silhouette,
     xlab = "Clusters",
     ylab = "Silhouette Width")
lines(1:10, silhouette)

pam <- pam(gower_df, diss = TRUE, k = 6)
# These are the median values of our clusters
# They represent the characteristics of each cluster
intrusion_df[pam$medoids, ]

# plot the data in 2-dimensional space
tsne_object <- Rtsne(gower_df, is_distance = TRUE)
tsne_df <- tsne_object$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam$clustering))

ggplot(aes(x = X, y = Y), data = tsne_df) +
  geom_point(aes(color = cluster))
```
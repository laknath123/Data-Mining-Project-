silhouette = c(silhouette, NA)
# calculate distances using medoids instead of centroids
# this takes a long time to run
for(i in 2:10){
pam_clusters = pam(as.matrix(gower_df),
diss = TRUE,
k = i)
silhouette = c(silhouette,pam_clusters$silinfo$avg.width)
}
library(Rtsne)
# plot silhouette widths based on number of clusters
plot(1:10, silhouette,
xlab = "Clusters",=
# source: https://towardsdatascience.com/clustering-datasets-having-both-numerical-and-categorical-variables-ed91cdca0677
# Clustering
intrusion_df <- filter(df, is_intrusion == 1)
# build a df of gower distances
library(cluster)
gower_df <- daisy(intrusion_df, metric="gower", type=list(logration=2))
summary(gower_df)
# calculate silhouette width to determine number of clusters
silhouette <- c()
silhouette = c(silhouette, NA)
# calculate distances using medoids instead of centroids
# this takes a long time to run
for(i in 2:10){
pam_clusters = pam(as.matrix(gower_df),
diss = TRUE,
k = i)
silhouette = c(silhouette,pam_clusters$silinfo$avg.width)
}
library(Rtsne)
# plot silhouette widths based on number of clusters
plot(1:10, silhouette,
xlab = "Clusters",
ylab = "Silhouette Width")
lines(1:10, silhouette)
pam <- pam(gower_df, diss = TRUE, k = 6)
# These are the median values of our clusters
# They represent the characteristics of each cluster
intrusion_df[pam$medoids, ]
# plot the data in 2-dimensional space
tsne_object <- Rtsne(gower_df, is_distance = TRUE)
tsne_df <- tsne_object$Y %>%
data.frame() %>%
setNames(c("X", "Y")) %>%
mutate(cluster = factor(pam$clustering))
ggplot(aes(x = X, y = Y), data = tsne_df) +
geom_point(aes(color = cluster))
# Logistic Regression
df.train
df.test
# Logistic Regression
df.train
# Logistic Regression
df.train[is.na(df.train)]
# Logistic Regression
df.train[is.na(df.train)][1]
# Logistic Regression
is.na(df.train)
# fit logistic regression on train set
glm.fits <- glm(is_intrusion∼., data=df.train,family=binomial)
# fit logistic regression on train set
glm.fits <- glm(is_intrusion∼., data=df.train,family=binomial, maxit = 100)
# Logistic Regression
df.train$is_intrusion <- as.factor(df.train$is_intrusion)
# fit logistic regression on train set
glm.fits <- glm(is_intrusion∼., data=df.train,family=binomial)
# Logistic Regression
typeof(is_intrusion)
# Logistic Regression
typeof(df.train$is_intrusion)
# Logistic Regression
typeof(df$is_intrusion)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
df <- read.csv("network_traffic.csv")
p21 <- qplot(df$is_hot_login, geom="bar")
p21
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
df <- read.csv("network_traffic.csv")
set.seed(1234)
# drop useless columns
df <- select(df, -c(num_outbound_cmds, land, num_failed_logins, wrong_fragment, urgent, is_host_login, su_attempted))
# Clean is_intrusion column
df$is_intrusion <- ifelse(df$is_intrusion == 1, 1, 0)
# make Yes/No variables more readable
df <- df %>%
mutate(is_intrusion = ifelse(is_intrusion == 0,"No","Yes")) %>%
mutate(protocol_type = ifelse(protocol_type == 0,"No","Yes")) %>%
mutate(service = ifelse(service == 0,"No","Yes")) %>%
mutate(flag = ifelse(flag == 0,"No","Yes")) %>%
mutate(logged_in = ifelse(logged_in == 0,"No","Yes")) %>%
mutate(root_shell = ifelse(root_shell == 0,"No","Yes")) %>%
mutate(is_guest_login = ifelse(is_guest_login == 0,"No","Yes"))
# convert to factors
df$is_intrusion <- as.factor(df$is_intrusion)
df$protocol_type <- as.factor(df$protocol_type)
df$service <- as.factor(df$service)
df$flag <- as.factor(df$flag)
df$logged_in <- as.factor(df$logged_in)
df$root_shell <- as.factor(df$root_shell)
df$is_guest_login <- as.factor(df$is_guest_login)
summary(df)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
df <- read.csv("network_traffic.csv")
set.seed(1234)
# drop useless columns
df <- select(df, -c(num_outbound_cmds, land, num_failed_logins, wrong_fragment, urgent, is_host_login, su_attempted))
# Clean is_intrusion column
df$is_intrusion <- ifelse(df$is_intrusion == 1, 1, 0)
summary(df$flag)
head(df$flag)
# make Yes/No variables more readable
df <- df %>%
mutate(is_intrusion = ifelse(is_intrusion == 0,"No","Yes")) %>%
mutate(logged_in = ifelse(logged_in == 0,"No","Yes")) %>%
mutate(root_shell = ifelse(root_shell == 0,"No","Yes")) %>%
mutate(is_guest_login = ifelse(is_guest_login == 0,"No","Yes"))
df$is_intrusion <- as.factor(df$is_intrusion)
df$protocol_type <- as.factor(df$protocol_type)
df$service <- as.factor(df$service)
df$flag <- as.factor(df$flag)
df$logged_in <- as.factor(df$logged_in)
df$root_shell <- as.factor(df$root_shell)
df$is_guest_login <- as.factor(df$is_guest_login)
summary(df)
# Upsample the data to artifically overcome sample imbalance
df.more.idx <- sample(which(df$is_intrusion == 1), 15000, replace = TRUE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
df <- read.csv("network_traffic.csv")
set.seed(1234)
# fit logistic regression on train set
glm.fits <- glm(is_intrusion∼., data=df.train ,family="binomial")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
df <- read.csv("network_traffic.csv")
set.seed(1234)
# drop useless columns
df <- select(df, -c(num_outbound_cmds, land, num_failed_logins, wrong_fragment, urgent, is_host_login, su_attempted))
# Clean is_intrusion column
df$is_intrusion <- ifelse(df$is_intrusion == 1, 1, 0)
# make Yes/No variables more readable
df <- df %>%
mutate(is_intrusion = ifelse(is_intrusion == 0,"No","Yes")) %>%
mutate(logged_in = ifelse(logged_in == 0,"No","Yes")) %>%
mutate(root_shell = ifelse(root_shell == 0,"No","Yes")) %>%
mutate(is_guest_login = ifelse(is_guest_login == 0,"No","Yes"))
# convert to factors
df$is_intrusion <- as.factor(df$is_intrusion)
df$protocol_type <- as.factor(df$protocol_type)
df$service <- as.factor(df$service)
df$flag <- as.factor(df$flag)
df$logged_in <- as.factor(df$logged_in)
df$root_shell <- as.factor(df$root_shell)
df$is_guest_login <- as.factor(df$is_guest_login)
# Upsample the data to artifically overcome sample imbalance
df.more.idx <- sample(which(df$is_intrusion == "Yes"), 15000, replace = TRUE)
df.upsample <- rbind(df,
df[df.more.idx, ])
# Randomly select 20% of the data to be held out for model validation
test.indexes <- sample(1:nrow(df.upsample),
round(0.2 * nrow(df.upsample)))
train.indexes <- setdiff(1:nrow(df.upsample), test.indexes)
df.train <- df.upsample[train.indexes,]
df.test <- df.upsample[test.indexes,]
p1 <- qplot(df$duration, geom="histogram", xlab="Duration")
p2 <- qplot(df$protocol_type, geom="bar", xlab="Protocol Type")
p3 <- qplot(df$service, geom="bar", xlab="Service")
p4 <- qplot(df$src_bytes, geom="histogram", xlab="Bytes from Source to Destination")
p5 <- qplot(df$dst_bytes, geom="histogram", xlab="Bytes from Destination to Source")
p6 <- qplot(df$flag, geom="bar", xlab="Error Status")
p7 <- qplot(df$hot, geom="histogram", xlab="Hot Indicators")
p8 <- qplot(df$logged_in, geom="bar", xlab="Logged In")
p9 <- qplot(df$num_compromised, geom="histogram", xlab="Number Compromised")
p10 <- qplot(df$root_shell, geom="bar", xlab="Root Shell")
p11 <- qplot(df$num_root, geom="histogram", xlab="Number of Root Commands")
p12 <- qplot(df$num_file_creations, geom="histogram", xlab="File Creations")
p13 <- qplot(df$num_shells, geom="histogram", xlab="Number of Shells")
p14 <- qplot(df$num_access_files, geom="histogram", xlab="Accessed Files")
p15 <- qplot(df$is_guest_login, geom="bar", xlab="Guest Login")
p16 <- qplot(df$is_intrusion, geom="bar", xlab="Intrusion")
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, ncol=3)
grid.arrange(p10, p12, p13, p14, p15, p16, ncol=3)
#Adding a boxplots src and dst bytes by service
options(scipen=999)
ggplot(data = df,aes(x = as.factor(service),y = src_bytes))+
geom_boxplot()+
coord_flip()+ylab("number of data bytes from source to destination ")+xlab("Service")
ggplot(data = df,aes(x = as.factor(service),y = dst_bytes))+
geom_boxplot()+
coord_flip()+
ylab("number of data bytes from destination to source")+xlab("Service")
ggplot(data = df,aes(x = as.factor(service),y = duration ))+
geom_boxplot()+
coord_flip()+xlab("Service Types")
classMetrics <- function(score, y, cutoff,
type = c("all", "accuracy", "sensitivity",
"specificity", "ppv", "npv", "precision",
"recall")) {
# classify the observations based on score and cutoff
observed <- y
predicted <- ifelse(score >= cutoff,1,0)
# Form confusion matrix
conf<-table(predicted,observed)
# Use the appropriate entries in the confusion matrix to calculate all metrics:
# accuracy, sensitivity, specificity, ppv, npv, precision (which is the same as ppv), recall (which is the same as sensitivity)
#accuracy <-
accuracy<- round((conf[4]+conf[1])/sum(conf),6)
sensitivity <- (conf[4])/(conf[3]+conf[4])
specificity <-  conf[1]/(conf[1]+conf[2])
ppv         <- conf[4]/(conf[4]+conf[2])
npv         <- conf[1]/(conf[1]+conf[3])
precision   <- ppv
recall      <- sensitivity
# I'm giving you the exact names you should use in your output dataframe
metric.names <- c("accuracy", "sensitivity", "specificity",
"ppv", "npv", "precision", "recall")
# Form into data frame
value <- c(accuracy, sensitivity, specificity,
ppv, npv, precision, recall)
# Your data frame should contain ONLY ONE COLUMN named "value"
# assign the metric.names above as the rownames of your data frame (just as the rownames, not as a second column!)
df <- data.frame(row.names = metric.names,value)
full_list<- list(conf,df)
names(full_list) <- c("conf.mat", "perf")
#full_list <<- full_list
# Return a list containing the confusion matrix and the data frame of the metrics
# If "all", return all metrics. Otherwise, return just the requested subset of metrics
if ("all" %in% type){
return(full_list)
} else {
full_list[[2]]<- full_list[[2]]%>%
filter(row.names(full_list[[2]]) %in% type)
return(full_list)
}
}
intrusion.tree <- rpart(is_intrusion ~ ., df.train)
plot(intrusion.tree)
text(intrusion.tree)
intrusion.party <- as.party(intrusion.tree)
plot(intrusion.party)
intrusion.full <- rpart(is_intrusion ~ ., data = df.train,
control = rpart.control(minsplit=100, cp=0.002))
# Run the `plotcp` command on this tree. Also look at the `cptable` attribute of `marketing.full`
plotcp(intrusion.full)
intrusion.full$cptable
mycp <- 0.002000000
intrusion.pruned<- prune(intrusion.full,cp= mycp)
print(intrusion.pruned)
df.pruned.party <- as.party(intrusion.pruned)
plot(df.pruned.party, gp = gpar(fontsize = 7))
my_pred<- predict(intrusion.pruned, df.test, type="prob")
classMetrics(my_pred[,1], df.test$is_intrusion,cutoff = 0.25)
intrusion.rf <- randomForest(is_intrusion ~.,data=df.train, importance=TRUE)
varImpPlot (intrusion.rf)
my_pred_forest<- predict(intrusion.rf,df.test,type="prob")
classMetrics(my_pred_forest[,1], df.test$is_intrusion,cutoff = 0.3)
classMetrics(my_pred_forest[,1], df.test$is_intrusion,cutoff = 0.25)
# fit logistic regression on train set
glm.fits <- glm(is_intrusion∼., data=df.train ,family="binomial")
summary(glm.fits)
# predict on test set
glm.probs <- predict(glm.fits,df.test, type="response")
cutoff <- 0.5
glm.pred <- 1:length(glm.probs)
glm.pred[glm.probs > cutoff] <- "Yes"
glm.pred[glm.probs < cutoff] <- "No"
table(glm.pred, df.test$is_intrusion)
varImp(glm.fits)
library(caret)
library(car)
varImp(glm.fits)
vif(glm.fits)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
library(caret)
df <- read.csv("network_traffic.csv")
set.seed(1234)
# fit logistic regression on train set
glm.fits <- glm(is_intrusion∼., data=df.train ,family="binomial", maxit=100)
summary(glm.fits)
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,    # 1 best model for each number of predictors
nvmax = NULL,    # NULL for no limit on number of variables
method = "exhaustive", really.big = TRUE)
library(glmnet)
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,    # 1 best model for each number of predictors
nvmax = NULL,    # NULL for no limit on number of variables
method = "exhaustive", really.big = TRUE)
library(leaps)
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,    # 1 best model for each number of predictors
nvmax = NULL,    # NULL for no limit on number of variables
method = "exhaustive", really.big = TRUE)
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,
nvmax = 10,
method = "exhaustive",
really.big = TRUE)
sum(is.na(df))
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,
nvmax = 10,
method = "exhaustive",
really.big = TRUE)
df.subset <- regsubsets(is_intrusion ~ . - is_intrusion,
data = df,
nbest = 1,
nvmax = 10,
method = "exhaustive",
really.big = TRUE)
df.subset <- regsubsets(is_intrusion ~ .,
data = df)
df.subset <- regsubsets(is_intrusion ~ service + flag,
data = df,
nbest = 1,
nvmax = 10,
method = "exhaustive",
really.big = TRUE)
summary(df$service)
summary(df)
summary(as.factor(df$service))
typeof(as.factor(df$service))
typeof(df$service)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(rpart) # added tree library
library(partykit)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggcorrplot)
library(randomForest)
library(cluster)
library(caret)
library(leaps)
df <- read.csv("network_traffic.csv")
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
set.seed(1234)
# drop useless columns
df <- select(df, -c(num_outbound_cmds, land, num_failed_logins, wrong_fragment, urgent, is_host_login, su_attempted))
# Clean is_intrusion column
df$is_intrusion <- ifelse(df$is_intrusion == 1, 1, 0)
# make Yes/No variables more readable
df <- df %>%
mutate(is_intrusion = ifelse(is_intrusion == 0,"No","Yes")) %>%
mutate(logged_in = ifelse(logged_in == 0,"No","Yes")) %>%
mutate(root_shell = ifelse(root_shell == 0,"No","Yes")) %>%
mutate(is_guest_login = ifelse(is_guest_login == 0,"No","Yes"))
typeof(df$is_guest_login)
typeof(as.factor(df$is_guest_login))
summary(df$is_guest_login)
summary(as.factor(df$is_guest_login))
summary(df$is_intrusion)
# convert to factors
df$is_intrusion <- as.factor(df$is_intrusion)
summary(df$is_intrusion)
df$protocol_type <- as.factor(df$protocol_type)
df$service <- as.factor(df$service)
df$flag <- as.factor(df$flag)
df$logged_in <- as.factor(df$logged_in)
df$root_shell <- as.factor(df$root_shell)
df$is_guest_login <- as.factor(df$is_guest_login)
# Upsample the data to artifically overcome sample imbalance
df.more.idx <- sample(which(df$is_intrusion == "Yes"), 15000, replace = TRUE)
df.upsample <- rbind(df,
df[df.more.idx, ])
# Randomly select 20% of the data to be held out for model validation
test.indexes <- sample(1:nrow(df.upsample),
round(0.2 * nrow(df.upsample)))
train.indexes <- setdiff(1:nrow(df.upsample), test.indexes)
df.train <- df.upsample[train.indexes,]
df.test <- df.upsample[test.indexes,]
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,
nvmax = 10,
method = "exhaustive",
really.big = TRUE)
# Add code below to answer the question
summary(df.subset)
length(df)
head(df)
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,
nvmax = NULL,
method = "exhaustive",
really.big = TRUE)
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,
nvmax = NULL,
method = "exhaustive",
really.big = TRUE)
nvmax = length(df) # all variables
df.subset_bestmodels <- list()
#Iterate to get the best model at each number of coeficients
#Remember that we limited our nvmax to 5!
for(i in 1:nvmax) {
df.subset_bestmodels[[i]] <- c(coef(lifexp.subset, i))
}
df.subset <- regsubsets(is_intrusion ~ .,
data = df,
nbest = 1,
nvmax = NULL,
method = "exhaustive",
really.big = TRUE)
nvmax = length(df) # all variables
df.subset_bestmodels <- list()
#Iterate to get the best model at each number of coeficients
#Remember that we limited our nvmax to 5!
for(i in 1:nvmax) {
df.subset_bestmodels[[i]] <- c(coef(df.subset, i))
}
df.subset_bestmodels
dfsummary<-summary(df.subset)
num_variables<-seq(1,length(df.summary$rss))
df.summary<-summary(df.subset)
num_variables<-seq(1,length(df.summary$rss))
plot_RSS<-ggplot(data = data.frame(df.summary$rss),
aes(x=num_variables,y=df.summary$rss))+
geom_line()+
geom_point(x=which.min(df.summary$rss),
y=min(df.summary$rss),aes(color="red"),
show.legend = FALSE)+
xlab("# Variables")+
ylab("RSS")+
theme_bw()
plot_R_sq<-ggplot(data = data.frame(df.summary$rsq),
aes(x=num_variables,y=df.summary.rsq))+
geom_line()+
geom_point(x=which.max(df.summary$rsq),
y=max(df.summary$rsq),aes(color="red"),
show.legend = FALSE)+
xlab("# Variables")+
ylab("R-sq")+
theme_bw()
plot_BIC<-ggplot(data = data.frame(df.summary$bic),
aes(x=num_variables,y=df.summary.bic))+
geom_line()+
geom_point(x=which.min(df.summary$bic),
y=min(df.summary$bic),aes(color="red"),
show.legend = FALSE)+
xlab("# Variables")+
ylab("BIC")+
theme_bw()
plot_AIC<-ggplot(data = data.frame(df.summary$cp),
aes(x=num_variables,y=df.summary.cp))+
geom_line()+
geom_point(x=which.min(df.summary$cp),
y=min(df.summary$cp),aes(color="red"),
show.legend = FALSE)+
xlab("# Variables")+
ylab("AIC")+
theme_bw()
grid.arrange(plot_RSS, plot_R_sq,plot_AIC,plot_BIC, ncol=2,nrow=2)
